# ðŸ“˜ Linear Regression â€“ Theory

Linear Regression is a **supervised learning algorithm** used to predict a continuous output based on input features.

---

## ðŸ§® Equation

> y = mx + c

- `y`: predicted value
- `x`: input feature
- `m`: slope (coefficient)
- `c`: intercept

In multiple dimensions:  
> y = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™ + b

---

## ðŸŽ¯ Objective

To find the best-fitting line by minimizing the **Mean Squared Error (MSE)**:
> MSE = (1/n) * Î£(yáµ¢ - Å·áµ¢)Â²

---

## ðŸ§  Use Cases

- Predicting house prices
- Estimating salaries
- Forecasting sales

---

## ðŸ“Š Evaluation Metric

- **RÂ² Score** (Coefficient of Determination)
  - Ranges from 0 to 1
  - Closer to 1 = better model fit

---

ðŸ“Œ For code implementation, see the notebook `linear_regression_sklearn.ipynb`.
