 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score

# ğŸ¯ Sample non-linear dataset
X = np.array([1, 2, 3, 4, 5, 6]).reshape(-1, 1)
y = np.array([3, 6, 11, 18, 27, 38])  

# ğŸ” Generate polynomial features (degree = 2)
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)

# ğŸ§  Train the regression model
model = LinearRegression()
model.fit(X_poly, y)

# ğŸ¯ Make predictions
y_pred = model.predict(X_poly)

# ğŸ“Š Evaluation
print("âœ… Coefficients:", model.coef_)
print("âœ… Intercept:", model.intercept_)
print("âœ… RÂ² Score:", r2_score(y, y_pred))

# ğŸ“ˆ Plotting actual vs predicted
plt.scatter(X, y, color='blue', label="Actual Data")
plt.plot(X, y_pred, color='red', label="Polynomial Fit (Degree 2)")
plt.xlabel("X")
plt.ylabel("y")
plt.title("Polynomial Regression Example")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
